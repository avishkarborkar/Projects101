# -*- coding: utf-8 -*-
"""Fashion_mnist_recognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UzLKLcyL_cIHH4mYuwOD8JRsVO7zW-k2
"""

import tensorflow as tf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

mnist = tf.keras.datasets.fashion_mnist
(train_image, train_label), (test_image, test_label) = mnist.load_data()

import numpy as np
import matplotlib.pyplot as plt

# You can put between 0 to 59999 here
index = 0

# Set number of characters per row when printing
np.set_printoptions(linewidth=500)

# Print the label and image
print(f'LABEL: {train_label[index]}')
print(f'\nIMAGE PIXEL ARRAY:\n {train_image[index]}')

# Visualize the image
plt.imshow(train_image[index])

train_image = train_image/255.0
test_image = test_image/255.0

# index = 0

# print(f"Label: {train_label[index]}")
# print(f'\nIMAGE PIXEL ARRAY:\n {train_image[index]}')

#Building a model with 128 neurons in the first layer and 10 in the output layer, Dense over here denotes that every neuron
#is connected to every other neuron present.
#Flatten is to set the pixels in an array of 28*28 = 728 rather than making a matrix of 28*28
#relu = rectified linear unit essentially -->
# if x > 0: 
#   return x

# else: 
#   return 0

model = tf.keras.models.Sequential(
    [
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation = 'relu'),
    tf.keras.layers.Dense(10, activation = 'softmax')
    ]
)

#sparse_categorical_crossentropy -Use sparse categorical crossentropy 
#when your classes are mutually exclusive (e.g. when each sample belongs exactly to one class)

model.compile(optimizer = tf.optimizers.Adam(),
              loss = 'sparse_categorical_crossentropy',
              metrics = ['accuracy'])

model.fit(train_image, train_label, epochs = 5)

model.evaluate(test_image, test_label)

classification = model.predict(test_image)
print(test_label[9])

mnist = tf.keras.datasets.fashion_mnist

(train_image, train_label), (test_image, test_label) = mnist.load_data()

model = tf.keras.models.Sequential([
                                    tf.keras.layers.Flatten(),
                                    tf.keras.layers.Dense(512, activation = 'relu'),
                                    tf.keras.layers.Dense(10, activation = 'softmax')
])

model.compile(optimizer = tf.optimizers.Adam(), loss = 'sparse_categorical_crossentropy')
model.fit(train_image, train_label, epochs = 10)

model.evaluate(test_image, test_label)
classif = model.predict(test_image)
print(classif[0])
print(test_image[0])

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy') >= 0.6): # Experiment with changing this value
      print("\nReached 60% accuracy so cancelling training!")
      self.model.stop_training = True

callbacks = myCallback()
mnist = tf.keras.datasets.fashion_mnist
(training_images, training_labels), (test_images, test_labels) = mnist.load_data()
training_images=training_images/255.0
test_images=test_images/255.0
model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(512, activation=tf.nn.relu),
  tf.keras.layers.Dense(10, activation=tf.nn.softmax)
])
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])